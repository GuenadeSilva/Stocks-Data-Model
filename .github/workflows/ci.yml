name: dbt CI

on:
  pull_request:
    branches:
      - main

jobs:
  dbt_run:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read # Required to download artifacts

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GCP_CREDENTIALS_JSON }}'

      - name: 'Create BigQuery Keyfile'
        run: |
          echo '${{ secrets.GCP_CREDENTIALS_JSON }}' > /tmp/bigquery_keyfile.json

      # --- Run dbt in "Slim" mode ---
      # 1. We change the dataset to a temporary CI schema.
      # 2. We use state:modified+ to run only changed models and children.
      - name: Run dbt (Slim CI)
        env:
          BIGQUERY_PROJECT: 'stocks-data-model'
          # Creates a unique schema for this PR (e.g., dbt_ci_42)
          BIGQUERY_DATASET: 'dbt_ci_${{ github.event.number }}'
          BIGQUERY_KEYFILE_PATH: '/tmp/bigquery_keyfile.json'
        run: |
          dbt deps --project-dir stocks_data_model --profiles-dir stocks_data_model

          dbt build --project-dir stocks_data_model --profiles-dir stocks_data_model \
          --target ci
